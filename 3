import os
import google.generativeai as genai
from google.generativeai.types import GenerationConfig

def generate_answer(prompt: str, temperature: float, max_tokens: int):
    """ä½¿ç”¨ Gemini Pro API æ ¹æ“šæº«åº¦å’Œæœ€å¤§ token æ•¸é‡ç”Ÿæˆå›ç­”"""
    gemini_api_key = os.getenv("AIzaSyDceM6k-RNXffnGd-l0-EcMbLxZHL88GZA")
    if not gemini_api_key:
        raise ValueError("âŒ æœªè¨­å®š GEMINI_API_KEY ç’°å¢ƒè®Šæ•¸")
    
    genai.configure(api_key=gemini_api_key)
    model = genai.GenerativeModel('gemini-pro')

    generation_config = GenerationConfig(
        temperature=temperature,
        max_output_tokens=max_tokens
    )

    result = model.generate_content(prompt, generation_config=generation_config)
    return result.text

def main():
    final_prompt = "ç”¨ç°¡å–®çš„æ–¹å¼è§£é‡‹ä»€éº¼æ˜¯äººå·¥æ™ºæ…§ã€‚"

    print("\n" + "#" * 70)
    print("ğŸ”¥ æº«åº¦ (temperature) å½±éŸ¿æ¸¬è©¦")
    print("#" * 70)
    temperatures = [0.0, 0.5, 1.0]
    max_tokens_fixed = 200

    for temp in temperatures:
        print("\n" + "=" * 50)
        print(f"æº«åº¦: {temp} | æœ€å¤§è¼¸å‡º Token æ•¸: {max_tokens_fixed}")
        print("=" * 50)
        try:
            response = generate_answer(final_prompt, temperature=temp, max_tokens=max_tokens_fixed)
            print(response.strip())
        except Exception as e:
            print(f"âŒ ç”¢ç”Ÿå›ç­”éŒ¯èª¤ï¼Œæº«åº¦={temp}: {e}")

    print("\n" + "#" * 70)
    print("â³ æœ€å¤§è¼¸å‡ºé•·åº¦ (max_tokens) å½±éŸ¿æ¸¬è©¦")
    print("#" * 70)
    temperature_fixed = 0.5
    max_tokens_list = [20, 50, 200]

    for max_tokens in max_tokens_list:
        print("\n" + "=" * 50)
        print(f"æº«åº¦: {temperature_fixed} | æœ€å¤§è¼¸å‡º Token æ•¸: {max_tokens}")
        print("=" * 50)
        try:
            response = generate_answer(final_prompt, temperature=temperature_fixed, max_tokens=max_tokens)
            print(response.strip())
        except Exception as e:
            print(f"âŒ ç”¢ç”Ÿå›ç­”éŒ¯èª¤ï¼Œmax_tokens={max_tokens}: {e}")

if __name__ == "__main__":
    main()
